# from __future__ import annotations

# import asyncio
# from dataclasses import dataclass
# from typing import Union

# from pydantic_ai import Agent
# from pydantic_ai.messages import ModelMessage, ModelRequest, ModelResponse
# from pydantic_graph import BaseNode, End, Graph, GraphRunContext

# from agents.models import (
#     State,
#     FollowUpQuestions,
#     RefinedPrompt,
#     ExecutionPlan,
#     ExecutionResult,
# )
# from agents.agents import (
#     clarify_agent,
#     refine_agent,
#     outline_agent,
#     plan_evaluate_agent,
#     execute_agent,
#     report_agent,
# )

# import chainlit as cl


# @dataclass
# class Clarify(BaseNode[State]):
#     user_prompt: str
#     max_turns: int = 3

#     async def run(self, ctx: GraphRunContext[State]) -> Union[Outline, Elicit]:
#         ctx.state.num_clarify_turns += 1
#         print("ğŸ’¡ Clarification Agent is analyzing the request...")

#         if ctx.state.num_clarify_turns <= self.max_turns:
#             response = await clarify_agent.run(
#                 self.user_prompt, message_history=ctx.state.clarify_history
#             )
#             ctx.state.clarify_history = response.all_messages()
#         else:
#             response = await refine_agent.run(
#                 self.user_prompt, message_history=ctx.state.clarify_history
#             )
#         result = response.output

#         print(f"ğŸ¤– Agent response: {result}\n")

#         if isinstance(result, FollowUpQuestions):
#             print("â“ Agent determined more information is needed.")
#             return Elicit(follow_up=result)

#         if isinstance(result, RefinedPrompt):
#             print("âœ… Agent created a refined prompt.")
#             print(f"âœ¨ Refined Prompt: {result}\n")
#             ctx.state.user_prompt = result.refined_prompt
#             return Outline(prompt=result.refined_prompt)

#         raise TypeError(f"Unexpected agent output type: {type(result)}")


# @dataclass
# class Elicit(BaseNode[State]):
#     follow_up: FollowUpQuestions

#     async def run(self, ctx: GraphRunContext[State]) -> Clarify:
#         agent_message_content = "\n".join(f"  - {q}" for q in self.follow_up.questions)
#         print(f"ğŸ¤– Agent asks:\n{agent_message_content}\n")

#         await asyncio.sleep(1)
#         user_response = "I'm playing PokÃ©mon Emerald. My team is Marshtomp, and I want to beat the Elite Four."
#         print(f"ğŸ‘¤ User responds: {user_response}\n")
#         return Clarify(user_prompt=user_response)


# @dataclass
# class Outline(BaseNode[State]):
#     prompt: str

#     async def run(self, ctx: GraphRunContext[State]) -> PlanEvaluate:
#         print("ğŸ“ Planning agent is now taking over...")
#         print(f"   Input for planning phase: {ctx.state.user_prompt}")
#         response = await outline_agent.run(self.prompt)
#         ctx.state.research_outline = response.output.plan
#         print(f"ğŸ“‹ Research Plan created:\n{ctx.state.research_outline}\n")
#         return PlanEvaluate()


# @dataclass
# class PlanEvaluate(BaseNode[State]):
#     max_turns: int = 5

#     async def run(self, ctx: GraphRunContext[State]) -> Union[Execute, Report]:
#         if ctx.state.num_evaluate_turns >= self.max_turns:
#             print(
#                 f"âš ï¸ Max turns ({self.max_turns}) reached. Proceeding to final report."
#             )
#             return Report()

#         ctx.state.num_evaluate_turns += 1

#         response = await plan_evaluate_agent.run(deps=ctx.state)
#         plan: ExecutionPlan = response.output

#         if plan.is_complete:
#             print("âœ… Research phase complete. Final thoughts from the agent:")
#             print(plan.thoughts)
#             return Report()
#         else:
#             print("ğŸ¤” Agent thoughts for the next step:")
#             print(plan.thoughts)
#             if plan.queries:
#                 print("ğŸ“ New queries to execute:")
#                 for i, query in enumerate(plan.queries, start=1):
#                     print(f"  {i}. {query}")
#                 return Execute(plan=plan)
#             else:
#                 print(
#                     "âš ï¸ Agent decided to continue but generated no queries. Forcing report."
#                 )
#                 return Report()


# @dataclass
# class Execute(BaseNode[State]):
#     plan: ExecutionPlan

#     async def run(self, ctx: GraphRunContext[State]) -> PlanEvaluate:
#         print("ğŸ” Execution agent is processing the plan...")
#         queries = self.plan.queries
#         tasks = [execute_agent.run(query, deps=ctx.state) for query in queries]
#         responses = await asyncio.gather(*tasks)
#         for query, response in zip(queries, responses):
#             tool_message = response.all_messages()[2].parts[0]
#             tool_name = tool_message.tool_name
#             tool_output = tool_message.content
#             print(f"ğŸ”§ Tool '{tool_name}' executed for query: {query}")
#             ctx.state.execution_results.append(
#                 ExecutionResult(
#                     query=query,
#                     tool_name=tool_name,
#                     tool_output=tool_output,
#                     is_success=response.output.is_success,
#                     summary=response.output.summary,
#                 )
#             )

#         return PlanEvaluate()


# @dataclass
# class Report(BaseNode[State]):
#     async def run(self, ctx: GraphRunContext[State]) -> End:
#         print("ğŸ“Š Reporting agent is summarizing the results...")
#         response = await report_agent.run(deps=ctx.state)
#         ctx.state.report = response.output
#         print(f"ğŸ“„ Final Report:\n{ctx.state.report}\n")
#         return End(data=ctx.state)


# async def main():
#     initial_prompt = "What Pokemon should I add next to my party?"
#     print(f"ğŸ‘¤ User (initial prompt): {initial_prompt}\n")
#     initial_state = State()
#     graph = Graph(nodes=(Clarify, Elicit, Outline, PlanEvaluate, Execute, Report))

#     return await graph.run(Clarify(user_prompt=initial_prompt), state=initial_state)

from __future__ import annotations

import asyncio
from dataclasses import dataclass
from typing import Union

from pydantic_graph import BaseNode, End, GraphRunContext
from agents.models import (
    State,
    FollowUpQuestions,
    RefinedPrompt,
    ExecutionPlan,
    ExecutionResult,
)
from agents.agents import (
    clarify_agent,
    refine_agent,
    outline_agent,
    plan_evaluate_agent,
    execute_agent,
    report_agent,
)

import chainlit as cl


# @dataclass
# class Clarify(BaseNode[State]):
#     user_prompt: str
#     max_turns: int = 3

#     async def run(self, ctx: GraphRunContext[State]) -> Union[Outline, Elicit]:
#         ctx.state.num_clarify_turns += 1
#         if ctx.state.num_clarify_turns <= self.max_turns:
#             response = await clarify_agent.run(
#                 self.user_prompt, message_history=ctx.state.clarify_history
#             )
#         else:
#             response = await refine_agent.run(
#                 self.user_prompt, message_history=ctx.state.clarify_history
#             )

#         ctx.state.clarify_history = response.all_messages()
#         result = response.output

#         if isinstance(result, FollowUpQuestions):
#             return Elicit(follow_up=result)

#         if isinstance(result, RefinedPrompt):
#             ctx.state.user_prompt = result.refined_prompt
#             return Outline(prompt=result.refined_prompt)


# @dataclass
# class Elicit(BaseNode[State]):
#     follow_up: FollowUpQuestions

#     async def run(self, ctx: GraphRunContext[State]) -> Clarify:
#         user_response = "I'm playing PokÃ©mon Emerald. My team is Marshtomp, and I want to beat the Elite Four."
#         return Clarify(user_prompt=user_response)


@dataclass
class Outline(BaseNode[State]):
    prompt: str

    async def run(self, ctx: GraphRunContext[State]) -> PlanEvaluate:
        step = cl.Step(name="ğŸ“ Creating Outline", type="run")
        await step.send()

        response = await outline_agent.run(self.prompt)
        ctx.state.research_outline = response.output.plan

        await step.stream_token(f"ğŸ“‹ Outline:\n{ctx.state.research_outline}")
        await step.update()

        return PlanEvaluate()


@dataclass
class PlanEvaluate(BaseNode[State]):
    max_turns: int = 5

    async def run(self, ctx: GraphRunContext[State]) -> Union[Execute, Report]:
        step = cl.Step(
            name=f"ğŸ§  Planning Turn {ctx.state.num_evaluate_turns + 1}", type="run"
        )
        await step.send()

        if ctx.state.num_evaluate_turns >= self.max_turns:
            await step.stream_token(
                "âš ï¸ Max planning steps reached. Proceeding to report."
            )
            await step.update()
            return Report()

        ctx.state.num_evaluate_turns += 1

        response = await plan_evaluate_agent.run(deps=ctx.state)
        plan: ExecutionPlan = response.output

        if plan.thoughts:
            await step.stream_token(f"ğŸ’­ Thoughts:\n{plan.thoughts}\n")

        if plan.is_complete:
            await step.stream_token("âœ… Research complete. Generating report...")
            await step.update()
            return Report()

        if plan.queries:
            queries = "\n".join(f"- {q}" for q in plan.queries)
            await step.stream_token(f"ğŸ“Œ New Queries:\n{queries}")
            await step.update()
            return Execute(plan=plan)

        await step.stream_token("âš ï¸ No queries generated. Ending early.")
        await step.update()
        return Report()


@dataclass
class Execute(BaseNode[State]):
    plan: ExecutionPlan

    async def run(self, ctx: GraphRunContext[State]) -> PlanEvaluate:
        step = cl.Step(name="ğŸ”§ Executing Queries", type="run")
        await step.send()

        queries = self.plan.queries
        tasks = [execute_agent.run(query, deps=ctx.state) for query in queries]
        responses = await asyncio.gather(*tasks)

        for query, response in zip(queries, responses):
            tool_message = response.all_messages()[2].parts[0]
            tool_name = tool_message.tool_name
            tool_output = tool_message.content
            summary = response.output.summary

            ctx.state.execution_results.append(
                ExecutionResult(
                    query=query,
                    tool_name=tool_name,
                    tool_output=tool_output,
                    is_success=response.output.is_success,
                    summary=summary,
                )
            )

            await step.stream_token(
                f"ğŸ” `{tool_name}` ran on _{query}_:\nğŸ—’ï¸ {summary}\n"
            )

        await step.update()
        return PlanEvaluate()


@dataclass
class Report(BaseNode[State]):
    async def run(self, ctx: GraphRunContext[State]) -> End:
        step = cl.Step(name="ğŸ“Š Generating Report", type="run")
        await step.send()

        response = await report_agent.run(deps=ctx.state)
        ctx.state.report = response.output

        await step.stream_token("âœ… Report complete.")
        await step.update()
        await asyncio.sleep(0.1)
        await cl.Message(
            content=f"ğŸ“„ **Final Report:**\n\n{ctx.state.report}",
            author="Agent",
        ).send()

        return End(data=ctx.state)
